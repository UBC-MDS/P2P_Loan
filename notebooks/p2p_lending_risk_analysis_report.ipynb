{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0d408b-7e89-4a98-a803-dbf7a108e338",
   "metadata": {},
   "source": [
    "## P2P Online Lending Default Prediction- A Usecase on LendingClub Default Risk\n",
    "\n",
    "Mavis Wong, Yasmin Hassan and Abeba N. Turi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f30627-8d74-4a41-838f-72dc89e0e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import os\n",
    "from hashlib import sha1\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import pandera as pa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Enable the VegaFusion data transformer\n",
    "#alt.data_transformers.enable(\"vegafusion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51db056-9c1c-4248-98ab-8dbbe3b03670",
   "metadata": {},
   "source": [
    "### 1. Summary<br>\n",
    "This work intends to leaverage machine learning models to predict borrower behaviour and hence probability of default. More specifically, the work focuses aszxon predicting loan defaults using historical data from the Lending Club platform. By applying advanced preprocessing techniques, exploratory data analysis (EDA), and a Logistic Regression model, we uncover patterns and trends in borrower risk profiles. The final model demonstrated strong performance on unseen test data, achieving an accuracy of 84.0%. Out of 1,916 test cases, the model correctly predicted 1,608 cases, with 308 incorrect predictions. These errors included both false positives (predicting a loan default when it didn’t occur) and false negatives (failing to predict an actual default).\n",
    "While false negatives pose a greater risk in financial decision-making, this model provides actionable insights to improve risk management and reduce potential financial losses for the platform. Despite its promising predictive capabilities, further research is needed to enhance the model's accuracy and better understand the characteristics of misclassified loans. Such improvements could play a crucial role in minimizing financial risks and maximizing the model’s effectiveness in peer-to-peer lending platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c1030-d547-4295-befa-7ab74fb6b3f0",
   "metadata": {},
   "source": [
    "### 2. Introduction <br>\n",
    "Crowd-based business models are one of the last decade’s developments with the proliferation of platform economies and web technology applications (see Sutherland and Jarrahi, 2018). One of such developments following the 2007 financial crisis are the P2P online lending platforms. The backbone of the digital economic system built on this is that it relies on trust a currency. Like all other crowd-based business models, P2P online lending heavily relied on trustworthiness of borrowers. To help with this, online platforms like LendingClub used a number of features to define eligibility and rate of access to loan for potential borrowers.Traditional credit risk analysis often relies on rule-based systems or credit scores, which might not fully capture the complexities of borrower behavior. By applying Logistic Regression, we aim to develop a model that is both interpretable and effective in identifying high-risk loans. This analysis intends to provide a data-driven approach to improve credit decision-making in a broader context of platform based transactions through machine learning models.\n",
    "Extensive research has been conducted on borrower risk behaviour analysis and trust within P2P online lending system, highlighting the critical role trust and predictability holds in ensuring platform sustainability and mitigating default risks (Cai, et al, 2016 and Lenz, 2016). Building on this, this work focuses on developing a comprehensive risk analysis framework through machine hlearning models that will help predict borrower behaviour.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17818120-85d2-40db-9840-9b838e5bc9a8",
   "metadata": {},
   "source": [
    "### 3. Methods <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fbe0af-8015-4025-b684-eb4a4a37102f",
   "metadata": {},
   "source": [
    "#### 3.1 Data <br>\n",
    "##### Data Source\n",
    "This analysis is based on the historic loan data from LendingClub (LendingClub. (n.d.) and Matmcreative. (n.d.).).\n",
    "It contains various borrower and loan features, such as interest rates, annual income, debt-to-income ratio (DTI), and credit history. The target variable, not.fully.paid, indicates whether the borrower defaulted on the loan (1) or successfully repaid it (0).\n",
    "\n",
    "##### Feature Description\n",
    "The key features taken into account for this analysis are:\n",
    "\n",
    "`purpose`: The purpose of the loan\n",
    "\n",
    "`int.rate`: Interest rate of the loan the applicant received \n",
    "\n",
    "`installment`: Monthly payment for the loan the applicant received.\n",
    "\n",
    "`log.annual.inc`: annual_income (growth rate)\n",
    "\n",
    "`dti`: Debt-to-income ratio\n",
    "\n",
    "`revol.bal`: Total credit revolving balance\n",
    "\n",
    "`revol.util`: Revolving line utilization rate\n",
    "\n",
    "`inq.last.6mths`: The number of inquiries in past 6 months\n",
    "\n",
    "`delinq.2yrs`: Delinquencies on lines of credit in the last 2 years.\n",
    "\n",
    "`pub.rec`: The number of derogatory public records\n",
    "\n",
    "`fico`: FICO credit score\n",
    "\n",
    "`days.with.cr.line`: Days with Credit Line\n",
    "\n",
    "`not.fully.paid`: Binary response on weather the loan is paid or not.\n",
    "\n",
    "##### Data Splitting to Training and Testing Data\n",
    "\n",
    "Train-Test Split: \n",
    "\n",
    "The dataset was split into training (80%) and test (20%) sets, resulting in 1916 observations in the test set.\n",
    "Features: The model was trained on both numeric features (e.g., int.rate, installment) and categorical features (e.g., purpose, loan_categories).\n",
    "\n",
    "Preprocessing: \n",
    "\n",
    "Numeric features were scaled using StandardScaler, while categorical features were one-hot encoded. Missing values were imputed using the median (numeric) or most frequent value (categorical).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7430cb6f-aed7-47e2-981e-eaa941e0e031",
   "metadata": {},
   "source": [
    "#### 3.2 Analysis <br>\n",
    "- Train-Test Split:\n",
    "The dataset was split into training (80%) and test (20%) sets, resulting in 1916 observations in the test set. <br>\n",
    "\n",
    "- Features: \n",
    "The model was trained on both numeric features (e.g., int.rate, installment) and categorical features (e.g., purpose, loan_categories).\n",
    "\n",
    "- Preprocessing: \n",
    "Numeric features were scaled using StandardScaler, while categorical features were one-hot encoded. Missing values were imputed using the median (numeric) or most frequent value (categorical).\n",
    "\n",
    "- Model:\n",
    "Logistic Regression was selected as the final model for its simplicity, slightly higher accuracy, and interpretability. \n",
    "All columns except `risk_category` were used in model fitting. `risk_category` was drop due to it being redundant to \"loan_categories\" (both derived from \"fico\" score).\n",
    "A grid search with 10-fold cross-validation on the hyperparameter `C` of the logistic regression model is used for optimization. \n",
    "Python language was used to conduct this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196daa7a-4a3e-4394-b06c-93bcc585d41c",
   "metadata": {},
   "source": [
    "### 4. Results and Discussion <br>\n",
    "\n",
    "In order for us to draw context about the data, let us have a look at the first few rows of the data; check the info about all columns, data types, and number of NaN values; and summary statistis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ff40a2a-8a93-458a-8a39-21b9a8b65a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit.policy</th>\n",
       "      <th>purpose</th>\n",
       "      <th>int.rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log.annual.inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days.with.cr.line</th>\n",
       "      <th>revol.bal</th>\n",
       "      <th>revol.util</th>\n",
       "      <th>inq.last.6mths</th>\n",
       "      <th>delinq.2yrs</th>\n",
       "      <th>pub.rec</th>\n",
       "      <th>not.fully.paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit.policy             purpose  int.rate  installment  log.annual.inc  \\\n",
       "0              1  debt_consolidation    0.1189       829.10       11.350407   \n",
       "1              1         credit_card    0.1071       228.22       11.082143   \n",
       "2              1  debt_consolidation    0.1357       366.86       10.373491   \n",
       "3              1  debt_consolidation    0.1008       162.34       11.350407   \n",
       "4              1         credit_card    0.1426       102.92       11.299732   \n",
       "\n",
       "     dti  fico  days.with.cr.line  revol.bal  revol.util  inq.last.6mths  \\\n",
       "0  19.48   737        5639.958333      28854        52.1               0   \n",
       "1  14.29   707        2760.000000      33623        76.7               0   \n",
       "2  11.63   682        4710.000000       3511        25.6               1   \n",
       "3   8.10   712        2699.958333      33667        73.2               1   \n",
       "4  14.97   667        4066.000000       4740        39.5               0   \n",
       "\n",
       "   delinq.2yrs  pub.rec  not.fully.paid  \n",
       "0            0        0               0  \n",
       "1            0        0               0  \n",
       "2            0        0               0  \n",
       "3            0        0               0  \n",
       "4            1        0               0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the project root directory (adjust the path if needed)\n",
    "project_root = os.path.abspath(os.path.join('..', '..', 'P2P_Loan_Risk-Analysis'))\n",
    "\n",
    "# Define the relative path to the data\n",
    "DATA_DIR = os.path.join(project_root, 'data', 'raw')\n",
    "file_path = os.path.join(DATA_DIR, 'loan_data.csv')\n",
    "\n",
    "p2ploan_df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Check the data\n",
    "p2ploan_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3d33df7-3c5d-482e-9f50-863323fab1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9578 entries, 0 to 9577\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   credit.policy      9578 non-null   int64  \n",
      " 1   purpose            9578 non-null   object \n",
      " 2   int.rate           9578 non-null   float64\n",
      " 3   installment        9578 non-null   float64\n",
      " 4   log.annual.inc     9578 non-null   float64\n",
      " 5   dti                9578 non-null   float64\n",
      " 6   fico               9578 non-null   int64  \n",
      " 7   days.with.cr.line  9578 non-null   float64\n",
      " 8   revol.bal          9578 non-null   int64  \n",
      " 9   revol.util         9578 non-null   float64\n",
      " 10  inq.last.6mths     9578 non-null   int64  \n",
      " 11  delinq.2yrs        9578 non-null   int64  \n",
      " 12  pub.rec            9578 non-null   int64  \n",
      " 13  not.fully.paid     9578 non-null   int64  \n",
      "dtypes: float64(6), int64(7), object(1)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "p2ploan_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d899c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit.policy</th>\n",
       "      <th>purpose</th>\n",
       "      <th>int.rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log.annual.inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days.with.cr.line</th>\n",
       "      <th>revol.bal</th>\n",
       "      <th>revol.util</th>\n",
       "      <th>inq.last.6mths</th>\n",
       "      <th>delinq.2yrs</th>\n",
       "      <th>pub.rec</th>\n",
       "      <th>not.fully.paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>829.10</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>19.48</td>\n",
       "      <td>737</td>\n",
       "      <td>5639.958333</td>\n",
       "      <td>28854</td>\n",
       "      <td>52.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>228.22</td>\n",
       "      <td>11.082143</td>\n",
       "      <td>14.29</td>\n",
       "      <td>707</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>33623</td>\n",
       "      <td>76.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>366.86</td>\n",
       "      <td>10.373491</td>\n",
       "      <td>11.63</td>\n",
       "      <td>682</td>\n",
       "      <td>4710.000000</td>\n",
       "      <td>3511</td>\n",
       "      <td>25.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>162.34</td>\n",
       "      <td>11.350407</td>\n",
       "      <td>8.10</td>\n",
       "      <td>712</td>\n",
       "      <td>2699.958333</td>\n",
       "      <td>33667</td>\n",
       "      <td>73.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>102.92</td>\n",
       "      <td>11.299732</td>\n",
       "      <td>14.97</td>\n",
       "      <td>667</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>4740</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9573</th>\n",
       "      <td>0</td>\n",
       "      <td>all_other</td>\n",
       "      <td>0.1461</td>\n",
       "      <td>344.76</td>\n",
       "      <td>12.180755</td>\n",
       "      <td>10.39</td>\n",
       "      <td>672</td>\n",
       "      <td>10474.000000</td>\n",
       "      <td>215372</td>\n",
       "      <td>82.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9574</th>\n",
       "      <td>0</td>\n",
       "      <td>all_other</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>257.70</td>\n",
       "      <td>11.141862</td>\n",
       "      <td>0.21</td>\n",
       "      <td>722</td>\n",
       "      <td>4380.000000</td>\n",
       "      <td>184</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9575</th>\n",
       "      <td>0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>97.81</td>\n",
       "      <td>10.596635</td>\n",
       "      <td>13.09</td>\n",
       "      <td>687</td>\n",
       "      <td>3450.041667</td>\n",
       "      <td>10036</td>\n",
       "      <td>82.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9576</th>\n",
       "      <td>0</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>351.58</td>\n",
       "      <td>10.819778</td>\n",
       "      <td>19.18</td>\n",
       "      <td>692</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9577</th>\n",
       "      <td>0</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>853.43</td>\n",
       "      <td>11.264464</td>\n",
       "      <td>16.28</td>\n",
       "      <td>732</td>\n",
       "      <td>4740.000000</td>\n",
       "      <td>37879</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9578 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit.policy             purpose  int.rate  installment  \\\n",
       "0                 1  debt_consolidation    0.1189       829.10   \n",
       "1                 1         credit_card    0.1071       228.22   \n",
       "2                 1  debt_consolidation    0.1357       366.86   \n",
       "3                 1  debt_consolidation    0.1008       162.34   \n",
       "4                 1         credit_card    0.1426       102.92   \n",
       "...             ...                 ...       ...          ...   \n",
       "9573              0           all_other    0.1461       344.76   \n",
       "9574              0           all_other    0.1253       257.70   \n",
       "9575              0  debt_consolidation    0.1071        97.81   \n",
       "9576              0    home_improvement    0.1600       351.58   \n",
       "9577              0  debt_consolidation    0.1392       853.43   \n",
       "\n",
       "      log.annual.inc    dti  fico  days.with.cr.line  revol.bal  revol.util  \\\n",
       "0          11.350407  19.48   737        5639.958333      28854        52.1   \n",
       "1          11.082143  14.29   707        2760.000000      33623        76.7   \n",
       "2          10.373491  11.63   682        4710.000000       3511        25.6   \n",
       "3          11.350407   8.10   712        2699.958333      33667        73.2   \n",
       "4          11.299732  14.97   667        4066.000000       4740        39.5   \n",
       "...              ...    ...   ...                ...        ...         ...   \n",
       "9573       12.180755  10.39   672       10474.000000     215372        82.1   \n",
       "9574       11.141862   0.21   722        4380.000000        184         1.1   \n",
       "9575       10.596635  13.09   687        3450.041667      10036        82.9   \n",
       "9576       10.819778  19.18   692        1800.000000          0         3.2   \n",
       "9577       11.264464  16.28   732        4740.000000      37879        57.0   \n",
       "\n",
       "      inq.last.6mths  delinq.2yrs  pub.rec  not.fully.paid  \n",
       "0                  0            0        0               0  \n",
       "1                  0            0        0               0  \n",
       "2                  1            0        0               0  \n",
       "3                  1            0        0               0  \n",
       "4                  0            1        0               0  \n",
       "...              ...          ...      ...             ...  \n",
       "9573               2            0        0               1  \n",
       "9574               5            0        0               1  \n",
       "9575               8            0        0               1  \n",
       "9576               5            0        0               1  \n",
       "9577               6            0        0               1  \n",
       "\n",
       "[9578 rows x 14 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Validation\n",
    "\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"credit.policy\": pa.Column(int, \n",
    "                                   checks=[\n",
    "                                    pa.Check(lambda s: s.isna().mean() <= 0.05,\n",
    "                                             element_wise=False,\n",
    "                                             error=\"Too many null values in 'credit.policy' column.\"),\n",
    "                                    pa.Check.isin([0, 1])], \n",
    "                                    nullable=True),\n",
    "        \"purpose\": pa.Column(\n",
    "            str,\n",
    "            pa.Check.isin([\n",
    "                \"debt_consolidation\", \n",
    "                \"all_other\", \n",
    "                \"credit_card\", \n",
    "                \"home_improvement\", \n",
    "                \"small_business\", \n",
    "                \"major_purchase\", \n",
    "                \"educational\"\n",
    "            ]),\n",
    "            nullable=True),\n",
    "        \"int.rate\": pa.Column(float, pa.Check.in_range(0, 1), nullable=True),\n",
    "        \"installment\": pa.Column(float, pa.Check.ge(0), nullable=True),\n",
    "        \"log.annual.inc\": pa.Column(float, pa.Check.ge(1), nullable=True),\n",
    "        \"dti\": pa.Column(float, pa.Check.ge(0), nullable=True),\n",
    "        \"fico\": pa.Column(int, pa.Check.in_range(300, 900), nullable=True),\n",
    "        \"days.with.cr.line\": pa.Column(float, pa.Check.ge(0), nullable=True),\n",
    "        \"revol.bal\": pa.Column(int, pa.Check.ge(0), nullable=True),\n",
    "        \"revol.util\": pa.Column(float, pa.Check.ge(0), nullable=True),\n",
    "        \"inq.last.6mths\": pa.Column(int, pa.Check.ge(0), nullable=True),\n",
    "        \"delinq.2yrs\": pa.Column(int, pa.Check.ge(0), nullable=True),\n",
    "        \"pub.rec\": pa.Column(int, pa.Check.ge(0), nullable=True),\n",
    "        \"not.fully.paid\": pa.Column(int, pa.Check.isin([0, 1]), nullable=True),\n",
    "    },\n",
    "    checks = [\n",
    "        pa.Check(lambda df: ~df.duplicated().any(), error=\"Duplicate rows found.\"),\n",
    "        pa.Check(lambda df: ~(df.isna().all(axis=1)).any(), error=\"Empty rows found.\")\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "schema.validate(p2ploan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e99db601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation matrix:\n",
      "                    credit.policy  int.rate  installment  log.annual.inc  \\\n",
      "credit.policy           1.000000 -0.294089     0.058770        0.034906   \n",
      "int.rate               -0.294089  1.000000     0.276140        0.056383   \n",
      "installment             0.058770  0.276140     1.000000        0.448102   \n",
      "log.annual.inc          0.034906  0.056383     0.448102        1.000000   \n",
      "dti                    -0.090901  0.220006     0.050202       -0.054065   \n",
      "fico                    0.348319 -0.714821     0.086039        0.114576   \n",
      "days.with.cr.line       0.099026 -0.124022     0.183297        0.336896   \n",
      "revol.bal              -0.187518  0.092527     0.233625        0.372140   \n",
      "revol.util             -0.104095  0.464837     0.081356        0.054881   \n",
      "inq.last.6mths         -0.535511  0.202780    -0.010419        0.029171   \n",
      "delinq.2yrs            -0.076318  0.156079    -0.004368        0.029203   \n",
      "pub.rec                -0.054243  0.098162    -0.032760        0.016506   \n",
      "not.fully.paid         -0.158119  0.159552     0.049955       -0.033439   \n",
      "\n",
      "                        dti      fico  days.with.cr.line  revol.bal  \\\n",
      "credit.policy     -0.090901  0.348319           0.099026  -0.187518   \n",
      "int.rate           0.220006 -0.714821          -0.124022   0.092527   \n",
      "installment        0.050202  0.086039           0.183297   0.233625   \n",
      "log.annual.inc    -0.054065  0.114576           0.336896   0.372140   \n",
      "dti                1.000000 -0.241191           0.060101   0.188748   \n",
      "fico              -0.241191  1.000000           0.263880  -0.015553   \n",
      "days.with.cr.line  0.060101  0.263880           1.000000   0.229344   \n",
      "revol.bal          0.188748 -0.015553           0.229344   1.000000   \n",
      "revol.util         0.337109 -0.541289          -0.024239   0.203779   \n",
      "inq.last.6mths     0.029189 -0.185293          -0.041736   0.022394   \n",
      "delinq.2yrs       -0.021792 -0.216340           0.081374  -0.033243   \n",
      "pub.rec            0.006209 -0.147592           0.071826  -0.031010   \n",
      "not.fully.paid     0.037362 -0.149666          -0.029237   0.053699   \n",
      "\n",
      "                   revol.util  inq.last.6mths  delinq.2yrs   pub.rec  \\\n",
      "credit.policy       -0.104095       -0.535511    -0.076318 -0.054243   \n",
      "int.rate             0.464837        0.202780     0.156079  0.098162   \n",
      "installment          0.081356       -0.010419    -0.004368 -0.032760   \n",
      "log.annual.inc       0.054881        0.029171     0.029203  0.016506   \n",
      "dti                  0.337109        0.029189    -0.021792  0.006209   \n",
      "fico                -0.541289       -0.185293    -0.216340 -0.147592   \n",
      "days.with.cr.line   -0.024239       -0.041736     0.081374  0.071826   \n",
      "revol.bal            0.203779        0.022394    -0.033243 -0.031010   \n",
      "revol.util           1.000000       -0.013880    -0.042740  0.066717   \n",
      "inq.last.6mths      -0.013880        1.000000     0.021245  0.072673   \n",
      "delinq.2yrs         -0.042740        0.021245     1.000000  0.009184   \n",
      "pub.rec              0.066717        0.072673     0.009184  1.000000   \n",
      "not.fully.paid       0.082088        0.149452     0.008881  0.048634   \n",
      "\n",
      "                   not.fully.paid  \n",
      "credit.policy           -0.158119  \n",
      "int.rate                 0.159552  \n",
      "installment              0.049955  \n",
      "log.annual.inc          -0.033439  \n",
      "dti                      0.037362  \n",
      "fico                    -0.149666  \n",
      "days.with.cr.line       -0.029237  \n",
      "revol.bal                0.053699  \n",
      "revol.util               0.082088  \n",
      "inq.last.6mths           0.149452  \n",
      "delinq.2yrs              0.008881  \n",
      "pub.rec                  0.048634  \n",
      "not.fully.paid           1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 9. Anomalous Correlations\n",
    "correlation_matrix = p2ploan_df.corr(numeric_only=True)\n",
    "print(\"Correlation matrix:\\n\", correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42169aa0-d256-43be-aaab-a72bc5d6c74d",
   "metadata": {},
   "source": [
    "#### 4.1 Data splitting \n",
    "\n",
    "Split the data into `train_df` (80%) and `test_df` (20%) with `random_state = 522`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aeee7d4-0c59-42ca-b459-0e96bbc5d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(p2ploan_df, test_size=0.2, random_state=522)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872e031a-faa1-40f9-a029-08f291ccfd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7662, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53548e9e-abae-4363-a2e5-09ec316a236b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit.policy</th>\n",
       "      <th>purpose</th>\n",
       "      <th>int.rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>log.annual.inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>fico</th>\n",
       "      <th>days.with.cr.line</th>\n",
       "      <th>revol.bal</th>\n",
       "      <th>revol.util</th>\n",
       "      <th>inq.last.6mths</th>\n",
       "      <th>delinq.2yrs</th>\n",
       "      <th>pub.rec</th>\n",
       "      <th>not.fully.paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7.662000e+03</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "      <td>7662.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.807883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122498</td>\n",
       "      <td>318.706990</td>\n",
       "      <td>10.932388</td>\n",
       "      <td>12.626631</td>\n",
       "      <td>710.975463</td>\n",
       "      <td>4574.926113</td>\n",
       "      <td>1.717180e+04</td>\n",
       "      <td>46.870501</td>\n",
       "      <td>1.566562</td>\n",
       "      <td>0.159358</td>\n",
       "      <td>0.062386</td>\n",
       "      <td>0.160141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.393990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026774</td>\n",
       "      <td>207.488994</td>\n",
       "      <td>0.614014</td>\n",
       "      <td>6.867246</td>\n",
       "      <td>37.763921</td>\n",
       "      <td>2508.344473</td>\n",
       "      <td>3.518355e+04</td>\n",
       "      <td>28.941005</td>\n",
       "      <td>2.166408</td>\n",
       "      <td>0.531531</td>\n",
       "      <td>0.263564</td>\n",
       "      <td>0.366761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>15.670000</td>\n",
       "      <td>7.547502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>180.041667</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>163.570000</td>\n",
       "      <td>10.555813</td>\n",
       "      <td>7.260000</td>\n",
       "      <td>682.000000</td>\n",
       "      <td>2820.000000</td>\n",
       "      <td>3.224250e+03</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>267.740000</td>\n",
       "      <td>10.918718</td>\n",
       "      <td>12.730000</td>\n",
       "      <td>707.000000</td>\n",
       "      <td>4140.041667</td>\n",
       "      <td>8.707500e+03</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139300</td>\n",
       "      <td>435.540000</td>\n",
       "      <td>11.289832</td>\n",
       "      <td>17.940000</td>\n",
       "      <td>737.000000</td>\n",
       "      <td>5730.041667</td>\n",
       "      <td>1.837150e+04</td>\n",
       "      <td>70.900000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>926.830000</td>\n",
       "      <td>14.180154</td>\n",
       "      <td>29.960000</td>\n",
       "      <td>827.000000</td>\n",
       "      <td>17639.958330</td>\n",
       "      <td>1.207359e+06</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        credit.policy             purpose     int.rate  installment  \\\n",
       "count     7662.000000                7662  7662.000000  7662.000000   \n",
       "unique            NaN                   7          NaN          NaN   \n",
       "top               NaN  debt_consolidation          NaN          NaN   \n",
       "freq              NaN                3172          NaN          NaN   \n",
       "mean         0.807883                 NaN     0.122498   318.706990   \n",
       "std          0.393990                 NaN     0.026774   207.488994   \n",
       "min          0.000000                 NaN     0.060000    15.670000   \n",
       "25%          1.000000                 NaN     0.103900   163.570000   \n",
       "50%          1.000000                 NaN     0.122100   267.740000   \n",
       "75%          1.000000                 NaN     0.139300   435.540000   \n",
       "max          1.000000                 NaN     0.216400   926.830000   \n",
       "\n",
       "        log.annual.inc          dti         fico  days.with.cr.line  \\\n",
       "count      7662.000000  7662.000000  7662.000000        7662.000000   \n",
       "unique             NaN          NaN          NaN                NaN   \n",
       "top                NaN          NaN          NaN                NaN   \n",
       "freq               NaN          NaN          NaN                NaN   \n",
       "mean         10.932388    12.626631   710.975463        4574.926113   \n",
       "std           0.614014     6.867246    37.763921        2508.344473   \n",
       "min           7.547502     0.000000   612.000000         180.041667   \n",
       "25%          10.555813     7.260000   682.000000        2820.000000   \n",
       "50%          10.918718    12.730000   707.000000        4140.041667   \n",
       "75%          11.289832    17.940000   737.000000        5730.041667   \n",
       "max          14.180154    29.960000   827.000000       17639.958330   \n",
       "\n",
       "           revol.bal   revol.util  inq.last.6mths  delinq.2yrs      pub.rec  \\\n",
       "count   7.662000e+03  7662.000000     7662.000000  7662.000000  7662.000000   \n",
       "unique           NaN          NaN             NaN          NaN          NaN   \n",
       "top              NaN          NaN             NaN          NaN          NaN   \n",
       "freq             NaN          NaN             NaN          NaN          NaN   \n",
       "mean    1.717180e+04    46.870501        1.566562     0.159358     0.062386   \n",
       "std     3.518355e+04    28.941005        2.166408     0.531531     0.263564   \n",
       "min     0.000000e+00     0.000000        0.000000     0.000000     0.000000   \n",
       "25%     3.224250e+03    22.800000        0.000000     0.000000     0.000000   \n",
       "50%     8.707500e+03    46.300000        1.000000     0.000000     0.000000   \n",
       "75%     1.837150e+04    70.900000        2.000000     0.000000     0.000000   \n",
       "max     1.207359e+06   119.000000       33.000000    13.000000     5.000000   \n",
       "\n",
       "        not.fully.paid  \n",
       "count      7662.000000  \n",
       "unique             NaN  \n",
       "top                NaN  \n",
       "freq               NaN  \n",
       "mean          0.160141  \n",
       "std           0.366761  \n",
       "min           0.000000  \n",
       "25%           0.000000  \n",
       "50%           0.000000  \n",
       "75%           0.000000  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Statistics\n",
    "train_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95927f-d60f-4c45-ae3c-e5651a3712cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us store the column names of the columns with missing values as a list in a variable called missing_vals_cols.\n",
    "missing_vals_cols = train_df.columns[train_df.isna().sum() > 0].tolist()\n",
    "\n",
    "# Define numeric columns explicitly\n",
    "numeric_cols = ['int.rate', 'installment', 'log.annual.inc', 'dti', 'fico', \n",
    "    'days.with.cr.line', 'revol.bal', 'revol.util', 'inq.last.6mths', 'annual.inc']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78203f10",
   "metadata": {},
   "source": [
    "### 4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aef94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income- level data\n",
    "train_df['annual.inc'] = np.exp(train_df['log.annual.inc'])\n",
    "test_df['annual.inc'] = np.exp(test_df['log.annual.inc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d8799",
   "metadata": {},
   "source": [
    "Here, from a business perspective, we need to identify high-risk and low-risk loan profiles to improve lending profitability while minimizing default rates. \n",
    "This includes assessing borrower behavior, income stability, and loan utilization to create a predictive model for effective risk categorization (see  Coşer et al., 2019 and Khandani et al.,2010).\n",
    "\n",
    "Key metrix and considerations:\n",
    "- Debt-to-Income Ratio \n",
    "- Credit Utilization Ratio( revol.util)_ how much of their revolving credit borrowers are using relative to their limit with higher values indicating possible financial strain.\n",
    "- Loan Duration vs. Risk: If longer-term loans are associated with higher default rate (days.with.cr.line).\n",
    "\n",
    "##### Loan categories\n",
    "Below, to help us create the loan categories, we are using the FICO risk profile categories  [see the Borrower risk profiles categories from here](https://www.consumerfinance.gov/data-research/consumer-credit-trends/student-loans/borrower-risk-profiles/#:~:text=We%20focus%20on%20five%20credit%20score%20levels%3A&text=Subprime%20(credit%20scores%20of%20580,scores%20of%20720%20or%20above)\n",
    "- Deep subprime (credit scores below 580)\n",
    "- Subprime (credit scores of 580-619)\n",
    "- Near-prime (credit scores of 620-659)\n",
    "- Prime (credit scores of 660-719)\n",
    "- Super-prime (credit scores of 720 or above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b720b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['loan_income_ratio'] = (train_df['installment'] * 12) / train_df['annual.inc']\n",
    "\n",
    "# Creating loan Categories\n",
    "conditions = [\n",
    "    (train_df['fico'] >= 720),\n",
    "    (train_df['fico'] < 719) & (train_df['fico'] >= 660),\n",
    "    (train_df['fico'] < 659) & (train_df['fico'] >= 620),\n",
    "    (train_df['fico'] < 619) & (train_df['fico'] >= 580),\n",
    "    (train_df['fico'] < 580)\n",
    "]\n",
    "loan_categories = ['Super-prime', 'Prime', 'Near-prime', 'Subprime', 'Deep subprime']\n",
    "train_df['loan_categories'] = np.select(conditions, loan_categories, default='Unknown')\n",
    "\n",
    "test_df['loan_income_ratio'] = (test_df['installment'] * 12) / test_df['annual.inc']\n",
    "conditions = [\n",
    "    (test_df['fico'] >= 720),\n",
    "    (test_df['fico'] < 719) & (test_df['fico'] >= 660),\n",
    "    (test_df['fico'] < 659) & (test_df['fico'] >= 620),\n",
    "    (test_df['fico'] < 619) & (test_df['fico'] >= 580),\n",
    "    (test_df['fico'] < 580)\n",
    "]\n",
    "test_df['loan_categories'] = np.select(conditions, loan_categories, default='Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33defcd0",
   "metadata": {},
   "source": [
    "##### Risk categories\n",
    "Let us explore the data further with specific borrower risk profile categories \n",
    "Based on the above 5 loan categories, we framed three main risk categories as high, medium and low risk profile with: \n",
    "fico score of at least 720 (Low Risk), 'fico' score between 650 and 720 ('Medium Risk') and 'fico' score of 650 as 'High Risk'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a02212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Risk Categories\n",
    "conditions = [\n",
    "    (train_df['fico'] >= 720),\n",
    "    (train_df['fico'] < 720) & (train_df['fico'] >= 650),\n",
    "    (train_df['fico'] < 650)\n",
    "]\n",
    "categories = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "train_df['risk_category'] = np.select(conditions, categories, default='Unknown')\n",
    "\n",
    "conditions = [\n",
    "    (test_df['fico'] >= 720),\n",
    "    (test_df['fico'] < 720) & (test_df['fico'] >= 650),\n",
    "    (test_df['fico'] < 650)\n",
    "]\n",
    "test_df['risk_category'] = np.select(conditions, categories, default='Unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db665b",
   "metadata": {},
   "source": [
    "#### 4.3 Descriptive Analysis- EDA\n",
    "\n",
    "To evaluate the usefulness of predictors for identifying loan defaults, we conducted an exploratory data analysis. Features such as int.rate (interest rate) and dti (debt-to-income ratio) displayed notable differences between borrowers who fully paid their loans and those who defaulted. For example, loans with higher interest rates (int.rate) were associated with a greater likelihood of default, while borrowers with lower debt-to-income ratios (dti) were less likely to default. Categorical features like purpose also provided significant insights; loans categorized under \"small business\" and \"credit card\" showed higher default rates compared to others, such as \"home improvement.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca163ebe-3764-4368-912f-50af421af6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in numeric_cols:\n",
    "    train_df.groupby(\"not.fully.paid\")[feat].plot.hist(bins=40, alpha=0.4, legend=True, density=True, title = \"Histogram of \" + feat)\n",
    "    plt.xlabel(feat)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48768d5b-8853-42aa-8ea9-4e995dbce1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data distribution of selected loan features\n",
    "numeric_cols_hists = alt.Chart(train_df).mark_bar().encode(\n",
    "    alt.X(alt.repeat(), type='quantitative', bin=alt.Bin(maxbins=20)),  \n",
    "    y='count()'\n",
    ").properties(\n",
    "    width=250,\n",
    "    height=175\n",
    ").repeat(\n",
    "    ['installment', 'dti'],  \n",
    "    columns=3\n",
    ")\n",
    "\n",
    "numeric_cols_hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1219e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Rate by Loan Purpose:\n",
    "\n",
    "# Explode 'purpose' column for analysis\n",
    "loan_purpose_data = train_df.explode('purpose')\n",
    "\n",
    "# Loan Category vs Loan Purpose\n",
    "purpose_risk_chart = alt.Chart(loan_purpose_data).mark_circle().encode(\n",
    "    x=alt.X('loan_categories:N', title='Loan Categories', sort='-color', axis=alt.Axis(labelAngle=0)),\n",
    "    y=alt.Y('purpose:N', title='Loan Purpose', sort='color'),\n",
    "    color=alt.Color('count()', scale=alt.Scale(scheme='viridis'), title='Loan Count'),\n",
    "    size=alt.Size('count()', title='Loan Count', scale=alt.Scale(range=[50, 1500])),\n",
    "    tooltip=['purpose', 'loan_categories', 'count()']\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400,\n",
    "    title=\"Loan Category vs Loan Purpose\"\n",
    ")\n",
    "\n",
    "purpose_risk_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df2b1c",
   "metadata": {},
   "source": [
    "We have a high concentration of loans in the medium risk category and significant number low risk borrowers as compared to the high risk borrowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d40100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories_hist = alt.Chart(train_df).mark_bar().encode(\n",
    "    x=alt.X('risk_category:N', title='Risk Categories', axis=alt.Axis(labelAngle=0)),  \n",
    "    y=alt.Y('count()', title='Count') \n",
    ").properties(\n",
    "    height=300,\n",
    "    width=400,\n",
    "    title=\"Distribution of Risk Categories\"\n",
    ")\n",
    "\n",
    "categories_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fico by loan purpose\n",
    "purpose_fico_boxplot = alt.Chart(loan_purpose_data).mark_boxplot().encode(\n",
    "    y=alt.Y('purpose:N', title='Loan Purpose', sort='-x'),  \n",
    "    x=alt.X('fico:Q', title='FICO Score', scale=alt.Scale(domain=[600, 850]),),  \n",
    "    color=alt.Color('purpose:N', legend=None),  \n",
    "    tooltip=['purpose', 'fico']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=200,\n",
    "    title='Boxplot of FICO Scores by Loan Purpose'\n",
    ")\n",
    "\n",
    "\n",
    "#Debt to income ratio by risk level\n",
    "risk_dti_boxplot = alt.Chart(train_df).mark_boxplot().encode(\n",
    "    y=alt.Y('risk_category:N', title='Risk Category', sort='-x'),  \n",
    "    x=alt.X('dti:Q', title='DTI (Debt-to-Income)', scale=alt.Scale(domain=[0, 50])),  \n",
    "    color=alt.Color('risk_category:N', legend=None),  \n",
    "    tooltip=['risk_category', 'dti']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=200,\n",
    "    title='Boxplot of DTI by Risk Category'\n",
    ")\n",
    "\n",
    "\n",
    "purpose_fico_boxplot & risk_dti_boxplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ea915",
   "metadata": {},
   "source": [
    "From the boxplot above, we see that the low risk borrowers have lower average debt-to-income-ratio as compared to the borrowers with medium and high risk profile, based on their fico score. Note also the outliers in FICO scores for the loan purpose of debt consolidation type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5867cfb7-5b3c-4cc6-bb92-c37bb2dae617",
   "metadata": {},
   "source": [
    "#### 4.4 Correlation Analysis\n",
    "The EDA for most of the numerical columns produce no strong general trends. \n",
    "We see a higher correlation level between fico and revo.util, and that of fico and interest rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a0cb2-1270-4ef0-89c5-f4de31bfc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = train_df[['int.rate', 'installment', 'log.annual.inc', 'dti', \n",
    "                         'fico', 'days.with.cr.line', 'revol.bal', 'revol.util', \n",
    "                         'inq.last.6mths', 'annual.inc']]\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_cols.corr().reset_index().melt('index')\n",
    "correlation_matrix.columns = ['Variable 1', 'Variable 2', 'Correlation']\n",
    "\n",
    "# Create a heatmap using Altair\n",
    "correlation_chart = alt.Chart(correlation_matrix).mark_rect().encode(\n",
    "    x=alt.X('Variable 1:N', title='', axis=alt.Axis(labelAngle=-45)),\n",
    "    y=alt.Y('Variable 2:N', title=''),\n",
    "    color=alt.Color('Correlation:Q', scale=alt.Scale(scheme='viridis')),\n",
    "    tooltip=['Variable 1', 'Variable 2', 'Correlation']\n",
    ").properties(\n",
    "    width=400,\n",
    "    height=400,\n",
    "    title=\"Correlation Heatmap\"\n",
    ")\n",
    "\n",
    "correlation_chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b803e-1469-4ea3-aa7a-f4d696ba70ef",
   "metadata": {},
   "source": [
    "####  4.5 Data Transformation and Preprocessing <br>\n",
    "Since both `risk_category` and `loan_categories` are dereived from `fico`, we decided to drop the `fico` and `risk_category` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321b848-c7c3-40df-8b5f-7802ad8b6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "# Features\n",
    "X_train = train_df.drop(columns=['not.fully.paid'])  \n",
    "X_test = test_df.drop(columns=['not.fully.paid' ]) \n",
    "\n",
    "# Target\n",
    "y_train = train_df['not.fully.paid']               \n",
    "y_test = test_df['not.fully.paid']               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d698c7-9a2f-4e1b-9368-8f036057c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric and categorical columns\n",
    "numeric_features = [\n",
    "    'int.rate', 'installment', 'annual.inc', 'loan_income_ratio', 'dti', \n",
    "    'days.with.cr.line', 'revol.bal', 'revol.util', \"fico\",\n",
    "    'inq.last.6mths', 'delinq.2yrs', 'pub.rec', \"credit.policy\"\n",
    "]\n",
    "categorical_features = ['purpose', \"loan_categories\"]\n",
    "\n",
    "# Preprocessing\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values\n",
    "    ('scaler', StandardScaler())                   # Scale numeric features\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # Encode categorical features\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8059b4-95a9-43a7-84c9-3969619bad20",
   "metadata": {},
   "source": [
    "####  4.6 Model Building<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cb357",
   "metadata": {},
   "source": [
    "First we performed 10-folds cross-evaluation on four classifier models: DecisionTree, kNN-neighbours, SVC and Logistic Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e58fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "knn = KNeighborsClassifier(n_jobs=-1)\n",
    "svc = SVC(random_state=123)\n",
    "log_reg = LogisticRegression(random_state=123)\n",
    "\n",
    "models = {\"Decision Tree\": dt, \n",
    "          \"kNN\": knn,\n",
    "          \"SVC\": svc,\n",
    "          \"Logistic Regression\": log_reg}\n",
    "\n",
    "\n",
    "def model_cross_val(model):\n",
    "\n",
    "    '''Perform 10-fold cross-validation on the given machine learning model \n",
    "    using a preprocessing pipeline. Returns a dictionary'''\n",
    "    \n",
    "    model_pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),  \n",
    "            ('model', model)\n",
    "    ])\n",
    "\n",
    "    results = pd.DataFrame(cross_validate(\n",
    "        model_pipeline, X_train, y_train, return_train_score=True, cv=10\n",
    "    ))\n",
    "\n",
    "    mean_std = pd.DataFrame({\"mean\":results.mean(),\n",
    "                             \"stdev\":results.std()})\n",
    "    \n",
    "    result_dict = {index: f\"{mu:.3f}(+/-{std:.3f})\" # Concat std with mean\n",
    "                   for (index, mu, std) in mean_std.itertuples()}\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "cv_results = pd.DataFrame()\n",
    "for (name, model) in models.items():\n",
    "    cv_results[name] = model_cross_val(model)\n",
    "cv_results = cv_results.T\n",
    "\n",
    "cv_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a45a30",
   "metadata": {},
   "source": [
    "From the mean validation score and training score, we can see that the decision tree model has a much smaller cross-validation score compared to the other three models. \n",
    "\n",
    "While the SVC model has a slightly larger test score than the logistic model, it requires a significantly longer computation time. Since the test score for SVC and Logistic Regression is very similar (both being ~0.84), We have opt for the logistic regression model as our predictor. \n",
    "\n",
    "The train score of the Logistic Regression is the same as the validation score, suggesting that the model is likely not overfitted and will be able to generalize well to unseen data. While together with the fact that SVC has a significantly longer computation time,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Tuning\n",
    "log_reg_param_dist = {\n",
    "    \"LogReg__C\": np.logspace(-5, 5)\n",
    "}\n",
    "\n",
    "log_reg_pipe = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('LogReg', LogisticRegression(random_state=123, max_iter=20000))\n",
    "])\n",
    "\n",
    "log_reg_search = GridSearchCV(\n",
    "    log_reg_pipe,\n",
    "    param_grid=log_reg_param_dist,\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "log_reg_search.fit(X_train, y_train)\n",
    "cv_results = pd.DataFrame(log_reg_search.cv_results_)[[\n",
    "    \"rank_test_score\",\n",
    "    \"param_LogReg__C\",\n",
    "    \"mean_test_score\",\n",
    "    \"mean_train_score\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b724e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.sort_values(by=\"rank_test_score\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa83dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log_reg = log_reg_search.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Model Accuracy: {accuracy_log_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd90b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_true = pd.DataFrame({\"prediction\":y_pred_log_reg, \"true\":y_test})\n",
    "results_log_reg = pd.DataFrame(\n",
    "    {   \n",
    "         \" \": [\"True Positive (defaulted)\", \"True Negative (fully paid)\"],\n",
    "        \"Predict Positive (defaulted)\": [\n",
    "            len(pred_true.query(\"prediction == 1 & true == 1\")),\n",
    "            len(pred_true.query(\"prediction == 1 & true == 0\"))\n",
    "            \n",
    "        ],\n",
    "        \"Predict Negative (fully paid)\": [\n",
    "            len(pred_true.query(\"prediction == 0 & true == 1\")),\n",
    "            len(pred_true.query(\"prediction == 0 & true == 0\"))\n",
    "    \n",
    "        ]\n",
    "    }\n",
    ")\n",
    "results_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891f5bc",
   "metadata": {},
   "source": [
    "Here, we identify the top 5 influential features for predicting each class.\n",
    "The Logistic Regression's coefficients provide insights into feature importance, highlighting predictors such as:\n",
    "\n",
    "fico: Higher credit score were strongly correlated with lower default risk.\n",
    "\n",
    "loan_income_ratio: Borrowers with higher loan-to-income ratios exhibited a greater likelihood of default.\n",
    "\n",
    "purpose: Loan purposes like \"small business\" and \"home improvement\" were associated with defaulted loans while \"credit card\" and \"debt consolidation\" were associated with fully paid loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bcc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train)\n",
    "coefficients = log_reg_search.best_estimator_.named_steps['LogReg'].coef_[0]\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"features\":preprocessor.get_feature_names_out(),\n",
    "     \"negative coefficient\": coefficients}\n",
    ").sort_values(by=\"negative coefficient\", ascending=True, ignore_index=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1620d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\"features\":preprocessor.get_feature_names_out(),\n",
    "     \"positive coefficient\": coefficients}\n",
    ").sort_values(by=\"positive coefficient\", ascending=False, ignore_index=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf6287",
   "metadata": {},
   "source": [
    "On the test set, the model correctly predicted 1608 cases out of 1916, with 308 errors. \n",
    "These errors were distributed across false positives and false negatives. False negatives, representing cases where a defaulted loan was not flagged, pose a greater financial risk, as these borrowers are likely to incur losses. False positives, on the other hand, might result in stricter lending requirements for borrowers who would have successfully repaid their loans.\n",
    "\n",
    "Despite the high accuracy score, our model fails to identify most of the defaults loan where only 10 of the 306 actual defaulted loan (loan not paid) is being flagged. This suggest that the accuracy score is unable to fully reflect the model performance. Though our model is a great predictor in identifying negative loan defaults (over 99% of the fully paid cases identified), the high false negative makes its real life application limited. Further steps is needed to improve the model such that it can also predict defaulted loans well.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b9c30",
   "metadata": {},
   "source": [
    "#### 4.8 Limitations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7314a224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not.fully.paid\n",
       "0    0.839859\n",
       "1    0.160141\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"not.fully.paid\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566148c",
   "metadata": {},
   "source": [
    "As we check the distribution of the target, we can see that the proportion of borrowers that has repayed their loans is significantly higher than those who defaulted their loans. \n",
    "The class imbalance of the target results in the model predicting most cases as \"negative\" (fully paid). \n",
    "\n",
    "Possible solutions to the high false negtative include adjusting the `class_weight` hyperparameter or adjusting the decision threshold of the logistic model. Since accuracy might not fully reflect the model performance in the case of class imbalance, it would be good to include other evaluation metrics when evaulating model performance. \n",
    "\n",
    "Also, based on the feature importances obtained, additional feature engineering or feature selection can potentially improve model performance. \n",
    "\n",
    "To account for possible non-linear decision boundary, another alternative is to use a non-linear classification model, for example a decision tree, which can model complex non-linear decision boundaries better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b54e61c-a334-411a-ae04-d29c61c330eb",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. Cai, S., Lin, X., Xu, D., & Fu, X. (2016). Judging online peer-to-peer lending behavior: A comparison of first-time and repeated borrowing requests. Information & Management, 53(7), 857-867.Consumer\n",
    "2. Coşer, A., Maer-Matei, M. M., & Albu, C. (2019). PREDICTIVE MODELS FOR LOAN DEFAULT RISK ASSESSMENT. Economic Computation & Economic Cybernetics Studies & Research, 53(2).\n",
    "3. Equifax. (n.d.). *Credit score ranges.* Retrieved November 20, 2024, from [https://www.equifax.com/personal/education/credit/score/articles/-/learn/credit-score-ranges/](https://www.equifax.com/personal/education/credit/score/articles/-/learn/credit-score-ranges/)\n",
    "4. Financial Protection Bureau. (n.d.). *Borrower risk profiles: Student loans*. Retrieved November 20, 2024, from [https://www.consumerfinance.gov/data-research/consumer-credit-trends/student-loans/borrower-risk-profiles/](https://www.consumerfinance.gov/data-research/consumer-credit-trends/student-loans/borrower-risk-profiles/)\n",
    "5. Khandani, A. E., Kim, A. J., & Lo, A. W. (2010). Consumer credit-risk models via machine-learning algorithms. Journal of Banking & Finance, 34(11), 2767-2787.\n",
    "8. Lenz, R. (2016). Peer-to-peer lending: Opportunities and risks. European Journal of Risk Regulation, 7(4), 688-700\n",
    "9. myFICO. (n.d.). *What's in my FICO® Scores?* Retrieved November 20, 2024, from [https://www.myfico.com/credit-education/whats-in-your-credit-score](https://www.myfico.com/credit-education/whats-in-your-credit-score#:~:text=FICO%20Scores%20are%20calculated%20using,and%20credit%20mix%20(10%25)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486d65b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan_risk522",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
